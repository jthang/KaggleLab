{
 "metadata": {
  "name": "",
  "signature": "sha256:d3cb657a5613de1a6525fc6493478cc7318140331ef4c3551fe70aeb84ae72ea"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Data Science London<span/>\n",
      "<img src=\"../images/ds.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Random Forests\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preliminaries\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler, normalize\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "sns.set(style=\"white\")\n",
      "plt.rc(\"figure\", figsize=(10, 6))\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\", \"#467821\", \"#D55E00\",\n",
      "          \"#CC79A7\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\"]\n",
      "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_df = pd.read_csv(\"../data_science_london/data/train.csv\", header=None)\n",
      "y_df = pd.read_csv(\"../data_science_london/data/trainLabels.csv\", header=None)\n",
      "X_pred_df = pd.read_csv(\"../data_science_london/data/test.csv\", header=None)\n",
      "\n",
      "X = X_df.values\n",
      "y = y_df[0].values\n",
      "X_pred = X_pred_df.values\n",
      "X_combined = np.r_[X, X_pred]\n",
      "\n",
      "print X.shape, y.shape, X_pred.shape, X_combined.shape\n",
      "\n",
      "X_df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 40) (1000,) (9000, 40) (10000, 40)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>30</th>\n",
        "      <th>31</th>\n",
        "      <th>32</th>\n",
        "      <th>33</th>\n",
        "      <th>34</th>\n",
        "      <th>35</th>\n",
        "      <th>36</th>\n",
        "      <th>37</th>\n",
        "      <th>38</th>\n",
        "      <th>39</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td>...</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>    0.025596</td>\n",
        "      <td>   -0.024526</td>\n",
        "      <td>   -0.024088</td>\n",
        "      <td>   -0.002271</td>\n",
        "      <td>    1.092329</td>\n",
        "      <td>   -0.006250</td>\n",
        "      <td>    0.497342</td>\n",
        "      <td>   -0.037883</td>\n",
        "      <td>    0.026391</td>\n",
        "      <td>   -0.003597</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.030651</td>\n",
        "      <td>    0.022951</td>\n",
        "      <td>   -0.542491</td>\n",
        "      <td>   -0.011608</td>\n",
        "      <td>   -0.483507</td>\n",
        "      <td>    0.033371</td>\n",
        "      <td>    0.567185</td>\n",
        "      <td>    0.006849</td>\n",
        "      <td>   -0.892659</td>\n",
        "      <td>    0.609451</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>    1.008282</td>\n",
        "      <td>    1.016298</td>\n",
        "      <td>    0.979109</td>\n",
        "      <td>    0.970575</td>\n",
        "      <td>    4.538834</td>\n",
        "      <td>    0.989128</td>\n",
        "      <td>    2.118819</td>\n",
        "      <td>    2.232256</td>\n",
        "      <td>    1.001064</td>\n",
        "      <td>    1.013520</td>\n",
        "      <td>...</td>\n",
        "      <td>    1.011645</td>\n",
        "      <td>    1.001375</td>\n",
        "      <td>    2.239939</td>\n",
        "      <td>    1.022456</td>\n",
        "      <td>    2.121281</td>\n",
        "      <td>    1.007044</td>\n",
        "      <td>    2.227876</td>\n",
        "      <td>    0.997635</td>\n",
        "      <td>    2.022022</td>\n",
        "      <td>    2.045439</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   -3.365711</td>\n",
        "      <td>   -3.492086</td>\n",
        "      <td>   -2.695602</td>\n",
        "      <td>   -3.460471</td>\n",
        "      <td>  -16.421901</td>\n",
        "      <td>   -3.041250</td>\n",
        "      <td>   -7.224761</td>\n",
        "      <td>   -6.509084</td>\n",
        "      <td>   -3.145588</td>\n",
        "      <td>   -2.749812</td>\n",
        "      <td>...</td>\n",
        "      <td>   -3.379194</td>\n",
        "      <td>   -2.971125</td>\n",
        "      <td>   -7.840890</td>\n",
        "      <td>   -2.999564</td>\n",
        "      <td>   -7.124105</td>\n",
        "      <td>   -2.952358</td>\n",
        "      <td>   -5.452254</td>\n",
        "      <td>   -3.473913</td>\n",
        "      <td>   -8.051722</td>\n",
        "      <td>   -7.799086</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>   -0.669010</td>\n",
        "      <td>   -0.693937</td>\n",
        "      <td>   -0.698830</td>\n",
        "      <td>   -0.617557</td>\n",
        "      <td>   -1.801997</td>\n",
        "      <td>   -0.732265</td>\n",
        "      <td>   -0.838619</td>\n",
        "      <td>   -1.604037</td>\n",
        "      <td>   -0.677562</td>\n",
        "      <td>   -0.682220</td>\n",
        "      <td>...</td>\n",
        "      <td>   -0.659457</td>\n",
        "      <td>   -0.696032</td>\n",
        "      <td>   -2.121943</td>\n",
        "      <td>   -0.664550</td>\n",
        "      <td>   -1.879247</td>\n",
        "      <td>   -0.642861</td>\n",
        "      <td>   -1.059786</td>\n",
        "      <td>   -0.691162</td>\n",
        "      <td>   -2.220126</td>\n",
        "      <td>   -0.565041</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>    0.027895</td>\n",
        "      <td>   -0.033194</td>\n",
        "      <td>    0.008145</td>\n",
        "      <td>    0.002327</td>\n",
        "      <td>    0.862818</td>\n",
        "      <td>    0.027041</td>\n",
        "      <td>    0.582321</td>\n",
        "      <td>    0.018809</td>\n",
        "      <td>    0.022092</td>\n",
        "      <td>   -0.036110</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.049416</td>\n",
        "      <td>    0.049778</td>\n",
        "      <td>   -0.568262</td>\n",
        "      <td>   -0.028097</td>\n",
        "      <td>   -0.493575</td>\n",
        "      <td>    0.037732</td>\n",
        "      <td>    0.455474</td>\n",
        "      <td>    0.038284</td>\n",
        "      <td>   -0.855470</td>\n",
        "      <td>    0.779944</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>    0.762520</td>\n",
        "      <td>    0.682753</td>\n",
        "      <td>    0.661434</td>\n",
        "      <td>    0.640743</td>\n",
        "      <td>    3.843172</td>\n",
        "      <td>    0.671456</td>\n",
        "      <td>    1.913664</td>\n",
        "      <td>    1.438304</td>\n",
        "      <td>    0.741310</td>\n",
        "      <td>    0.665364</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.747031</td>\n",
        "      <td>    0.699917</td>\n",
        "      <td>    0.939348</td>\n",
        "      <td>    0.651374</td>\n",
        "      <td>    1.005795</td>\n",
        "      <td>    0.691800</td>\n",
        "      <td>    2.122157</td>\n",
        "      <td>    0.693535</td>\n",
        "      <td>    0.388698</td>\n",
        "      <td>    1.992193</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>    3.326246</td>\n",
        "      <td>    3.583870</td>\n",
        "      <td>    2.546507</td>\n",
        "      <td>    3.088738</td>\n",
        "      <td>   17.565345</td>\n",
        "      <td>    3.102997</td>\n",
        "      <td>    7.592666</td>\n",
        "      <td>    7.130097</td>\n",
        "      <td>    3.145258</td>\n",
        "      <td>    3.919426</td>\n",
        "      <td>...</td>\n",
        "      <td>    2.844792</td>\n",
        "      <td>    3.688047</td>\n",
        "      <td>    7.160379</td>\n",
        "      <td>    3.353631</td>\n",
        "      <td>    6.005818</td>\n",
        "      <td>    3.420561</td>\n",
        "      <td>    6.603499</td>\n",
        "      <td>    3.492548</td>\n",
        "      <td>    5.774120</td>\n",
        "      <td>    6.803984</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 40 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "                0            1            2            3            4   \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
        "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
        "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
        "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
        "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
        "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
        "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
        "\n",
        "                5            6            7            8            9   \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597   \n",
        "std       0.989128     2.118819     2.232256     1.001064     1.013520   \n",
        "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812   \n",
        "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220   \n",
        "50%       0.027041     0.582321     0.018809     0.022092    -0.036110   \n",
        "75%       0.671456     1.913664     1.438304     0.741310     0.665364   \n",
        "max       3.102997     7.592666     7.130097     3.145258     3.919426   \n",
        "\n",
        "          ...                30           31           32           33  \\\n",
        "count     ...       1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean      ...          0.030651     0.022951    -0.542491    -0.011608   \n",
        "std       ...          1.011645     1.001375     2.239939     1.022456   \n",
        "min       ...         -3.379194    -2.971125    -7.840890    -2.999564   \n",
        "25%       ...         -0.659457    -0.696032    -2.121943    -0.664550   \n",
        "50%       ...          0.049416     0.049778    -0.568262    -0.028097   \n",
        "75%       ...          0.747031     0.699917     0.939348     0.651374   \n",
        "max       ...          2.844792     3.688047     7.160379     3.353631   \n",
        "\n",
        "                34           35           36           37           38  \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean     -0.483507     0.033371     0.567185     0.006849    -0.892659   \n",
        "std       2.121281     1.007044     2.227876     0.997635     2.022022   \n",
        "min      -7.124105    -2.952358    -5.452254    -3.473913    -8.051722   \n",
        "25%      -1.879247    -0.642861    -1.059786    -0.691162    -2.220126   \n",
        "50%      -0.493575     0.037732     0.455474     0.038284    -0.855470   \n",
        "75%       1.005795     0.691800     2.122157     0.693535     0.388698   \n",
        "max       6.005818     3.420561     6.603499     3.492548     5.774120   \n",
        "\n",
        "                39  \n",
        "count  1000.000000  \n",
        "mean      0.609451  \n",
        "std       2.045439  \n",
        "min      -7.799086  \n",
        "25%      -0.565041  \n",
        "50%       0.779944  \n",
        "75%       1.992193  \n",
        "max       6.803984  \n",
        "\n",
        "[8 rows x 40 columns]"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Train-Test-Split"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "print \"Train data shape: %r, Train target shape: %r\" % (X_train.shape, y_train.shape)\n",
      "print \"Test data shape: %r, Test target shape: %r\" % (X_test.shape, y_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train data shape: (800, 40), Train target shape: (800,)\n",
        "Test data shape: (200, 40), Test target shape: (200,)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ss = StandardScaler()\n",
      "X_s = ss.fit_transform(X)\n",
      "X_pred_s = ss.fit_transform(X_pred)\n",
      "\n",
      "print X_s.shape, X_pred_s.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 40) (9000, 40)\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Get best features by forest model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees = ExtraTreesClassifier(n_estimators=100)\n",
      "trees.fit(X_s, y)\n",
      "pd.DataFrame(trees.feature_importances_).plot(kind='barh')\n",
      "selected_features = np.where(trees.feature_importances_ > 0.02)[0]\n",
      "\n",
      "X_train_selected = X_train[:, selected_features]\n",
      "X_test_selected = X_test[:, selected_features]\n",
      "print X_train_selected.shape, X_test_selected.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(800, 15) (200, 15)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAFtCAYAAAAqMk/SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUh95uJIkSeojD1eSJEl95OFKkiSpj/4/S2miZj1vvAMAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x104556950>"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Support Vector Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "svc = SVC(probability=True)\n",
      "\n",
      "params = {'gamma': np.logspace(-4, 0, 5)\n",
      "          }\n",
      "\n",
      "gs = GridSearchCV(svc, params, cv=3, \n",
      "                  scoring='accuracy', \n",
      "                  n_jobs=4,\n",
      "                  verbose=1)\n",
      "\n",
      "_ = gs.fit(X_train_selected, y_train)\n",
      "\n",
      "print \"GS Best Score: %0.2f\" % gs.best_score_\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=4)]: Done   1 jobs       | elapsed:    0.1s\n",
        "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.3s remaining:    0.2s\n",
        "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    0.6s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GS Best Score: 0.91\n",
        "GS Best Params: {'gamma': 0.01}\n",
        "CPU times: user 201 ms, sys: 32.2 ms, total: 233 ms\n",
        "Wall time: 912 ms\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "svc.set_params(**gs.best_params_)\n",
      "svc.fit(X_train_selected, y_train)\n",
      "\n",
      "training_accuracy = svc.score(X_train, y_train)\n",
      "test_accuracy = svc.score(X_test, y_test)\n",
      "\n",
      "print \"Training Score: %0.2f%%\" % (100 * training_accuracy)\n",
      "print \"Test Score: %0.2f%%\" % (100 * test_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "X.shape[1] = 40 should be equal to 15, the number of features at training time",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-65-e5fe0aa111e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \"\"\"\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    403\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[1;32m    404\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 40 should be equal to 15, the number of features at training time"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Extra Trees Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "et = ExtraTreesClassifier(n_estimators=50)\n",
      "et.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "{'bootstrap': False,\n",
        " 'compute_importances': None,\n",
        " 'criterion': 'gini',\n",
        " 'max_depth': None,\n",
        " 'max_features': 'auto',\n",
        " 'max_leaf_nodes': None,\n",
        " 'min_density': None,\n",
        " 'min_samples_leaf': 1,\n",
        " 'min_samples_split': 2,\n",
        " 'n_estimators': 50,\n",
        " 'n_jobs': 1,\n",
        " 'oob_score': False,\n",
        " 'random_state': None,\n",
        " 'verbose': 0}"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "et = ExtraTreesClassifier(n_estimators=50)\n",
      "\n",
      "params = {'max_depth': [2, 3, 4, 6, 8],\n",
      "          'min_samples_leaf': [3, 5, 7, 8, 10],\n",
      "          'max_features': [1.0, 0.3, 0.1],\n",
      "          }\n",
      "\n",
      "n_subsamples = 800\n",
      "X_small_train, y_small_train = X_train[:n_subsamples], y_train[:n_subsamples]\n",
      "\n",
      "gs = GridSearchCV(et, params, cv=3, \n",
      "                  scoring='accuracy', \n",
      "                  n_jobs=4,\n",
      "                  verbose=1)\n",
      "\n",
      "_ = gs.fit(X_small_train, y_small_train)\n",
      "\n",
      "print \"GS Best Score: %0.2f\" % gs.best_score_\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=4)]: Done   1 jobs       | elapsed:    0.1s\n",
        "[Parallel(n_jobs=4)]: Done  50 jobs       | elapsed:    1.2s\n",
        "[Parallel(n_jobs=4)]: Done 200 jobs       | elapsed:    5.1s\n",
        "[Parallel(n_jobs=4)]: Done 219 out of 225 | elapsed:    5.5s remaining:    0.2s\n",
        "[Parallel(n_jobs=4)]: Done 225 out of 225 | elapsed:    5.6s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GS Best Score: 0.86\n",
        "GS Best Params: {'max_features': 1.0, 'max_depth': 6, 'min_samples_leaf': 3}\n",
        "CPU times: user 777 ms, sys: 144 ms, total: 921 ms\n",
        "Wall time: 5.85 s\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "et.set_params(**gs.best_params_)\n",
      "et.fit(X_train_selected, y_train)\n",
      "\n",
      "training_accuracy = et.score(X_train, y_train)\n",
      "test_accuracy = et.score(X_test, y_test)\n",
      "\n",
      "print \"Training Score: %0.2f%%\" % (100 * training_accuracy)\n",
      "print \"Test Score: %0.2f%%\" % (100 * test_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Invalid parameter gamma for estimator ExtraTreesClassifier",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-38-a0693542c28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n\u001b[0;32m--> 256\u001b[0;31m                                      % (key, self.__class__.__name__))\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Invalid parameter gamma for estimator ExtraTreesClassifier"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Accuracy Score"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = cross_val_score(clf, pca.transform(X), y)\n",
      "\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (min): 98.20%\n",
        "CV Score (mean): 98.90%\n",
        "CV Score (max): 99.40%\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Generate Predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = pd.DataFrame(index=np.arange(1, len(X_pred) + 1))\n",
      "pred['Solution'] = clf.predict(pca.transform(X_pred))\n",
      "# pred.to_csv('gmm_pca.csv', index_label='ID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('../style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}