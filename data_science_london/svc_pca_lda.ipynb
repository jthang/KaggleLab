{
 "metadata": {
  "name": "",
  "signature": "sha256:95424ea1ab4a49c9becc4b6556ed7fb1da5b16bb3d0944075d49a60f1a3cfdb3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Data Science London<span/>\n",
      "<img src=\"../images/ds.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Random Forests\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preliminaries\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.preprocessing import StandardScaler, normalize\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.decomposition import PCA\n",
      "\n",
      "sns.set(style=\"white\")\n",
      "plt.rc(\"figure\", figsize=(10, 6))\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\", \"#467821\", \"#D55E00\",\n",
      "          \"#CC79A7\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\"]\n",
      "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class TransformWrapper(BaseEstimator):\n",
      "\n",
      "    def __init__(self, clf, transformation, fit_transform=True):\n",
      "        self.clf = clf\n",
      "        self.fit_transform = fit_transform\n",
      "        self.transformation = transformation\n",
      "\n",
      "    def fit(self, X, y=None):\n",
      "        if self.fit_transform:\n",
      "            self.transformation.fit(X)\n",
      "        _X = self._pretransform(X)\n",
      "        if y is None:\n",
      "            self.clf.fit(_X)\n",
      "        else:\n",
      "            self.clf.fit(_X, y)\n",
      "\n",
      "    def predict(self, X):\n",
      "        _X = self._pretransform(X)\n",
      "        return self.clf.predict(_X)\n",
      "\n",
      "    def predict_proba(self, X):\n",
      "        _X = self._pretransform(X)\n",
      "        return self.clf.predict_proba(_X)\n",
      "\n",
      "    def score(self, X, y):\n",
      "        y_pred = self.predict(X)\n",
      "        return accuracy_score(y, y_pred)\n",
      "    \n",
      "    def transform(self, X):\n",
      "        _X = self._pretransform(X)\n",
      "        return self.clf.transform(_X)\n",
      "\n",
      "    def _pretransform(self, X):\n",
      "        return self.transformation.transform(X)\n",
      "\n",
      "class FeatureMixer(BaseEstimator):\n",
      "\n",
      "    def __init__(self, clfs, ignorefit=False):\n",
      "        self.clfs = clfs\n",
      "        self.ignorefit = ignorefit\n",
      "\n",
      "    def fit_transform(self, X, y=None):\n",
      "        if not self.ignorefit:\n",
      "            self.fit(X, y)\n",
      "        return self.transform(X)\n",
      "\n",
      "    def fit(self, X, y=None):\n",
      "        if not self.ignorefit:\n",
      "            for clf in self.clfs:\n",
      "                new = clf.fit_transform(X, y)\n",
      "\n",
      "    def transform(self, X):\n",
      "        ans = None\n",
      "        for clf in self.clfs:\n",
      "            new = clf.transform(X)\n",
      "            if ans is None:\n",
      "                ans = new\n",
      "            else:\n",
      "                ans = np.hstack((ans, new))\n",
      "        return ans"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_df = pd.read_csv(\"../data_science_london/data/train.csv\", header=None)\n",
      "y_df = pd.read_csv(\"../data_science_london/data/trainLabels.csv\", header=None)\n",
      "X_pred_df = pd.read_csv(\"../data_science_london/data/test.csv\", header=None)\n",
      "\n",
      "X = X_df.values\n",
      "y = y_df[0].values\n",
      "X_pred = X_pred_df.values\n",
      "X_combined = np.r_[X, X_pred]\n",
      "\n",
      "print X.shape, y.shape, X_pred.shape, X_combined.shape\n",
      "\n",
      "X_df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 40) (1000,) (9000, 40) (10000, 40)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>30</th>\n",
        "      <th>31</th>\n",
        "      <th>32</th>\n",
        "      <th>33</th>\n",
        "      <th>34</th>\n",
        "      <th>35</th>\n",
        "      <th>36</th>\n",
        "      <th>37</th>\n",
        "      <th>38</th>\n",
        "      <th>39</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td>...</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>    0.025596</td>\n",
        "      <td>   -0.024526</td>\n",
        "      <td>   -0.024088</td>\n",
        "      <td>   -0.002271</td>\n",
        "      <td>    1.092329</td>\n",
        "      <td>   -0.006250</td>\n",
        "      <td>    0.497342</td>\n",
        "      <td>   -0.037883</td>\n",
        "      <td>    0.026391</td>\n",
        "      <td>   -0.003597</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.030651</td>\n",
        "      <td>    0.022951</td>\n",
        "      <td>   -0.542491</td>\n",
        "      <td>   -0.011608</td>\n",
        "      <td>   -0.483507</td>\n",
        "      <td>    0.033371</td>\n",
        "      <td>    0.567185</td>\n",
        "      <td>    0.006849</td>\n",
        "      <td>   -0.892659</td>\n",
        "      <td>    0.609451</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>    1.008282</td>\n",
        "      <td>    1.016298</td>\n",
        "      <td>    0.979109</td>\n",
        "      <td>    0.970575</td>\n",
        "      <td>    4.538834</td>\n",
        "      <td>    0.989128</td>\n",
        "      <td>    2.118819</td>\n",
        "      <td>    2.232256</td>\n",
        "      <td>    1.001064</td>\n",
        "      <td>    1.013520</td>\n",
        "      <td>...</td>\n",
        "      <td>    1.011645</td>\n",
        "      <td>    1.001375</td>\n",
        "      <td>    2.239939</td>\n",
        "      <td>    1.022456</td>\n",
        "      <td>    2.121281</td>\n",
        "      <td>    1.007044</td>\n",
        "      <td>    2.227876</td>\n",
        "      <td>    0.997635</td>\n",
        "      <td>    2.022022</td>\n",
        "      <td>    2.045439</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   -3.365711</td>\n",
        "      <td>   -3.492086</td>\n",
        "      <td>   -2.695602</td>\n",
        "      <td>   -3.460471</td>\n",
        "      <td>  -16.421901</td>\n",
        "      <td>   -3.041250</td>\n",
        "      <td>   -7.224761</td>\n",
        "      <td>   -6.509084</td>\n",
        "      <td>   -3.145588</td>\n",
        "      <td>   -2.749812</td>\n",
        "      <td>...</td>\n",
        "      <td>   -3.379194</td>\n",
        "      <td>   -2.971125</td>\n",
        "      <td>   -7.840890</td>\n",
        "      <td>   -2.999564</td>\n",
        "      <td>   -7.124105</td>\n",
        "      <td>   -2.952358</td>\n",
        "      <td>   -5.452254</td>\n",
        "      <td>   -3.473913</td>\n",
        "      <td>   -8.051722</td>\n",
        "      <td>   -7.799086</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>   -0.669010</td>\n",
        "      <td>   -0.693937</td>\n",
        "      <td>   -0.698830</td>\n",
        "      <td>   -0.617557</td>\n",
        "      <td>   -1.801997</td>\n",
        "      <td>   -0.732265</td>\n",
        "      <td>   -0.838619</td>\n",
        "      <td>   -1.604037</td>\n",
        "      <td>   -0.677562</td>\n",
        "      <td>   -0.682220</td>\n",
        "      <td>...</td>\n",
        "      <td>   -0.659457</td>\n",
        "      <td>   -0.696032</td>\n",
        "      <td>   -2.121943</td>\n",
        "      <td>   -0.664550</td>\n",
        "      <td>   -1.879247</td>\n",
        "      <td>   -0.642861</td>\n",
        "      <td>   -1.059786</td>\n",
        "      <td>   -0.691162</td>\n",
        "      <td>   -2.220126</td>\n",
        "      <td>   -0.565041</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>    0.027895</td>\n",
        "      <td>   -0.033194</td>\n",
        "      <td>    0.008145</td>\n",
        "      <td>    0.002327</td>\n",
        "      <td>    0.862818</td>\n",
        "      <td>    0.027041</td>\n",
        "      <td>    0.582321</td>\n",
        "      <td>    0.018809</td>\n",
        "      <td>    0.022092</td>\n",
        "      <td>   -0.036110</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.049416</td>\n",
        "      <td>    0.049778</td>\n",
        "      <td>   -0.568262</td>\n",
        "      <td>   -0.028097</td>\n",
        "      <td>   -0.493575</td>\n",
        "      <td>    0.037732</td>\n",
        "      <td>    0.455474</td>\n",
        "      <td>    0.038284</td>\n",
        "      <td>   -0.855470</td>\n",
        "      <td>    0.779944</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>    0.762520</td>\n",
        "      <td>    0.682753</td>\n",
        "      <td>    0.661434</td>\n",
        "      <td>    0.640743</td>\n",
        "      <td>    3.843172</td>\n",
        "      <td>    0.671456</td>\n",
        "      <td>    1.913664</td>\n",
        "      <td>    1.438304</td>\n",
        "      <td>    0.741310</td>\n",
        "      <td>    0.665364</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.747031</td>\n",
        "      <td>    0.699917</td>\n",
        "      <td>    0.939348</td>\n",
        "      <td>    0.651374</td>\n",
        "      <td>    1.005795</td>\n",
        "      <td>    0.691800</td>\n",
        "      <td>    2.122157</td>\n",
        "      <td>    0.693535</td>\n",
        "      <td>    0.388698</td>\n",
        "      <td>    1.992193</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>    3.326246</td>\n",
        "      <td>    3.583870</td>\n",
        "      <td>    2.546507</td>\n",
        "      <td>    3.088738</td>\n",
        "      <td>   17.565345</td>\n",
        "      <td>    3.102997</td>\n",
        "      <td>    7.592666</td>\n",
        "      <td>    7.130097</td>\n",
        "      <td>    3.145258</td>\n",
        "      <td>    3.919426</td>\n",
        "      <td>...</td>\n",
        "      <td>    2.844792</td>\n",
        "      <td>    3.688047</td>\n",
        "      <td>    7.160379</td>\n",
        "      <td>    3.353631</td>\n",
        "      <td>    6.005818</td>\n",
        "      <td>    3.420561</td>\n",
        "      <td>    6.603499</td>\n",
        "      <td>    3.492548</td>\n",
        "      <td>    5.774120</td>\n",
        "      <td>    6.803984</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 40 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 295,
       "text": [
        "                0            1            2            3            4   \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
        "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
        "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
        "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
        "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
        "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
        "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
        "\n",
        "                5            6            7            8            9   \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597   \n",
        "std       0.989128     2.118819     2.232256     1.001064     1.013520   \n",
        "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812   \n",
        "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220   \n",
        "50%       0.027041     0.582321     0.018809     0.022092    -0.036110   \n",
        "75%       0.671456     1.913664     1.438304     0.741310     0.665364   \n",
        "max       3.102997     7.592666     7.130097     3.145258     3.919426   \n",
        "\n",
        "          ...                30           31           32           33  \\\n",
        "count     ...       1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean      ...          0.030651     0.022951    -0.542491    -0.011608   \n",
        "std       ...          1.011645     1.001375     2.239939     1.022456   \n",
        "min       ...         -3.379194    -2.971125    -7.840890    -2.999564   \n",
        "25%       ...         -0.659457    -0.696032    -2.121943    -0.664550   \n",
        "50%       ...          0.049416     0.049778    -0.568262    -0.028097   \n",
        "75%       ...          0.747031     0.699917     0.939348     0.651374   \n",
        "max       ...          2.844792     3.688047     7.160379     3.353631   \n",
        "\n",
        "                34           35           36           37           38  \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean     -0.483507     0.033371     0.567185     0.006849    -0.892659   \n",
        "std       2.121281     1.007044     2.227876     0.997635     2.022022   \n",
        "min      -7.124105    -2.952358    -5.452254    -3.473913    -8.051722   \n",
        "25%      -1.879247    -0.642861    -1.059786    -0.691162    -2.220126   \n",
        "50%      -0.493575     0.037732     0.455474     0.038284    -0.855470   \n",
        "75%       1.005795     0.691800     2.122157     0.693535     0.388698   \n",
        "max       6.005818     3.420561     6.603499     3.492548     5.774120   \n",
        "\n",
        "                39  \n",
        "count  1000.000000  \n",
        "mean      0.609451  \n",
        "std       2.045439  \n",
        "min      -7.799086  \n",
        "25%      -0.565041  \n",
        "50%       0.779944  \n",
        "75%       1.992193  \n",
        "max       6.803984  \n",
        "\n",
        "[8 rows x 40 columns]"
       ]
      }
     ],
     "prompt_number": 295
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Train-Test-Split"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
      "\n",
      "print \"Train data shape: %r, Train target shape: %r\" % (X_train.shape, y_train.shape)\n",
      "print \"Test data shape: %r, Test target shape: %r\" % (X_test.shape, y_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train data shape: (700, 40), Train target shape: (700,)\n",
        "Test data shape: (300, 40), Test target shape: (300,)\n"
       ]
      }
     ],
     "prompt_number": 296
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###SVC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC(kernel='rbf', C=1000000, gamma=0.277777777778)\n",
      "svc.fit(X_train, y_train)\n",
      "scores = cross_val_score(svc, X, y)\n",
      "\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (mean): 51.00%\n"
       ]
      }
     ],
     "prompt_number": 297
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###SVC + PCA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca = PCA(n_components=12, whiten=True)\n",
      "pca.fit_transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 298,
       "text": [
        "array([[ 0.9728, -0.7771, -0.0537, ..., -1.4984,  1.8215, -0.1624],\n",
        "       [-0.2154,  0.118 ,  1.3507, ...,  0.2392,  0.1531,  0.963 ],\n",
        "       [ 0.9159,  1.8062, -1.1555, ..., -0.0108,  0.5554, -1.5712],\n",
        "       ..., \n",
        "       [ 1.7598,  0.2382,  2.8441, ..., -0.4897, -1.4051,  0.7518],\n",
        "       [-1.8569, -0.4578, -0.9231, ...,  1.2322, -1.5114, -2.024 ],\n",
        "       [ 0.0704, -1.1277, -1.6382, ..., -0.8911,  0.0411, -1.5429]])"
       ]
      }
     ],
     "prompt_number": 298
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc_pca = TransformWrapper(svc, pca, fit_transform=True)\n",
      "svc_pca.fit(X_train, y_train)\n",
      "scores = cross_val_score(svc_pca, X, y)\n",
      "\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (mean): 94.40%\n"
       ]
      }
     ],
     "prompt_number": 299
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###SVC + PCA + LDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = LDA(n_components=2)\n",
      "lda = TransformWrapper(lda, pca, fit_transform=True)\n",
      "lda.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fm = FeatureMixer([pca, lda], ignorefit=True)\n",
      "fm.transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 301,
       "text": [
        "array([[ 0.9728, -0.7771, -0.0537, ...,  1.8215, -0.1624,  2.1864],\n",
        "       [-0.2154,  0.118 ,  1.3507, ...,  0.1531,  0.963 , -0.7396],\n",
        "       [ 0.9159,  1.8062, -1.1555, ...,  0.5554, -1.5712, -1.9465],\n",
        "       ..., \n",
        "       [ 1.7598,  0.2382,  2.8441, ..., -1.4051,  0.7518,  1.9732],\n",
        "       [-1.8569, -0.4578, -0.9231, ..., -1.5114, -2.024 , -1.9277],\n",
        "       [ 0.0704, -1.1277, -1.6382, ...,  0.0411, -1.5429,  0.4975]])"
       ]
      }
     ],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = SVC(kernel='rbf', C=1000000, gamma=0.277777777778)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc_pca_lda = TransformWrapper(svc, fm, fit_transform=True)\n",
      "svc_pca_lda.fit(X_train, y_train)\n",
      "scores = cross_val_score(svc_pca_lda, X, y)\n",
      "\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'PCA' object has no attribute 'mean_'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-304-4cceefa382f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvc_pca_lda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvc_pca_lda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_pca_lda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"CV Score (mean): %0.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, score_func, pre_dispatch)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1151\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1152\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \"\"\"\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-217-10f535580acf>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pretransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-217-10f535580acf>\u001b[0m in \u001b[0;36m_pretransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pretransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFeatureMixer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseEstimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-217-10f535580acf>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mans\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/decomposition/pca.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \"\"\"\n\u001b[1;32m    393\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'mean_'"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy_score(y_test, svc_pca_lda.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 294,
       "text": [
        "0.92000000000000004"
       ]
      }
     ],
     "prompt_number": 294
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca = PCA(whiten=True)\n",
      "pca.fit(X_combined)\n",
      "pd.DataFrame(pca.explained_variance_ratio_).plot(kind = 'bar')\n",
      "n_components = np.where(np.cumsum(pca.explained_variance_ratio_) >= 0.85)[0][0]\n",
      "print n_components\n",
      "\n",
      "pca = PCA(n_components=n_components, whiten=True)\n",
      "pca.fit(X_combined)\n",
      "\n",
      "X_train_pca = pca.transform(X_train)\n",
      "X_test_pca = pca.transform(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAFzCAYAAAD8LEcHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10d6e8350>"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Get best features by forest model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees = ExtraTreesClassifier(n_estimators=100)\n",
      "trees.fit(X_s, y)\n",
      "pd.DataFrame(trees.feature_importances_).plot(kind='barh')\n",
      "selected_features = np.where(trees.feature_importances_ > 0.015)[0]\n",
      "\n",
      "X_selected = X[:, selected_features]\n",
      "X_pred_selected = X_pred[:, selected_features]\n",
      "print X_selected.shape, X_pred_selected.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 22) (9000, 22)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAFtCAYAAAAqMk/SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10ac37c50>"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Support Vector Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "svc = SVC(probability=True)\n",
      "\n",
      "params = {'gamma': np.logspace(-4, 0, 5)\n",
      "          }\n",
      "\n",
      "gs = GridSearchCV(svc, params, cv=3, \n",
      "                  scoring='accuracy', \n",
      "                  n_jobs=4,\n",
      "                  verbose=1)\n",
      "\n",
      "_ = gs.fit(X_selected, y)\n",
      "\n",
      "print \"GS Best Score: %0.2f\" % gs.best_score_\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=4)]: Done   1 jobs       | elapsed:    0.2s\n",
        "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.4s remaining:    0.3s\n",
        "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    0.8s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GS Best Score: 0.91\n",
        "GS Best Params: {'gamma': 0.01}\n",
        "CPU times: user 220 ms, sys: 38.6 ms, total: 259 ms\n",
        "Wall time: 1.02 s\n"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc.set_params(**gs.best_params_)\n",
      "svc.fit(pca.transform(X), y)\n",
      "\n",
      "scores = cross_val_score(svc, pca.transform(X), y)\n",
      "\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (min): 81.68%\n",
        "CV Score (mean): 83.70%\n",
        "CV Score (max): 84.73%\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Extra Trees Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "et = ExtraTreesClassifier(n_estimators=300)\n",
      "et.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 84,
       "text": [
        "{'bootstrap': False,\n",
        " 'compute_importances': None,\n",
        " 'criterion': 'gini',\n",
        " 'max_depth': None,\n",
        " 'max_features': 'auto',\n",
        " 'max_leaf_nodes': None,\n",
        " 'min_density': None,\n",
        " 'min_samples_leaf': 1,\n",
        " 'min_samples_split': 2,\n",
        " 'n_estimators': 300,\n",
        " 'n_jobs': 1,\n",
        " 'oob_score': False,\n",
        " 'random_state': None,\n",
        " 'verbose': 0}"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "et = ExtraTreesClassifier(n_estimators=50)\n",
      "\n",
      "params = {'max_features': [1, 0.3, 0.1]}\n",
      "\n",
      "gs = GridSearchCV(et, params, cv=10, \n",
      "                  scoring='accuracy', \n",
      "                  n_jobs=4,\n",
      "                  verbose=1)\n",
      "\n",
      "_ = gs.fit(X, y)\n",
      "\n",
      "print \"GS Best Score: %0.2f\" % gs.best_score_\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=4)]: Done   1 jobs       | elapsed:    0.1s\n",
        "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    1.1s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GS Best Score: 0.89\n",
        "GS Best Params: {'max_features': 0.3}\n",
        "CPU times: user 248 ms, sys: 48.6 ms, total: 297 ms\n",
        "Wall time: 1.31 s\n"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "et.set_params(**gs.best_params_)\n",
      "et.fit(X_selected, y)\n",
      "\n",
      "scores = cross_val_score(et, X, y)\n",
      "\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (min): 86.19%\n",
        "CV Score (mean): 87.40%\n",
        "CV Score (max): 89.22%\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Accuracy Score"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Generate Predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = pd.DataFrame(index=np.arange(1, len(X_pred) + 1))\n",
      "pred['Solution'] = clf.predict(pca.transform(X_pred))\n",
      "# pred.to_csv('gmm_pca.csv', index_label='ID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('../style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}