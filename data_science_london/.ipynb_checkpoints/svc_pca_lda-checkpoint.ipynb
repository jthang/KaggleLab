{
 "metadata": {
  "name": "",
  "signature": "sha256:590f0a9e2eefcfc374fa19b9d648687d6cdcafc423f1aac381f2f131d68ed5ea"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Data Science London<span/>\n",
      "<img src=\"../images/ds.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Random Forests\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preliminaries\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler, normalize\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "sns.set(style=\"white\")\n",
      "plt.rc(\"figure\", figsize=(10, 6))\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\", \"#467821\", \"#D55E00\",\n",
      "          \"#CC79A7\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\"]\n",
      "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_df = pd.read_csv(\"../data_science_london/data/train.csv\", header=None)\n",
      "y_df = pd.read_csv(\"../data_science_london/data/trainLabels.csv\", header=None)\n",
      "X_pred_df = pd.read_csv(\"../data_science_london/data/test.csv\", header=None)\n",
      "\n",
      "X = X_df.values\n",
      "y = y_df[0].values\n",
      "X_pred = X_pred_df.values\n",
      "X_combined = np.r_[X, X_pred]\n",
      "\n",
      "print X.shape, y.shape, X_pred.shape, X_combined.shape\n",
      "\n",
      "X_df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 40) (1000,) (9000, 40) (10000, 40)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>30</th>\n",
        "      <th>31</th>\n",
        "      <th>32</th>\n",
        "      <th>33</th>\n",
        "      <th>34</th>\n",
        "      <th>35</th>\n",
        "      <th>36</th>\n",
        "      <th>37</th>\n",
        "      <th>38</th>\n",
        "      <th>39</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td>...</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>    0.025596</td>\n",
        "      <td>   -0.024526</td>\n",
        "      <td>   -0.024088</td>\n",
        "      <td>   -0.002271</td>\n",
        "      <td>    1.092329</td>\n",
        "      <td>   -0.006250</td>\n",
        "      <td>    0.497342</td>\n",
        "      <td>   -0.037883</td>\n",
        "      <td>    0.026391</td>\n",
        "      <td>   -0.003597</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.030651</td>\n",
        "      <td>    0.022951</td>\n",
        "      <td>   -0.542491</td>\n",
        "      <td>   -0.011608</td>\n",
        "      <td>   -0.483507</td>\n",
        "      <td>    0.033371</td>\n",
        "      <td>    0.567185</td>\n",
        "      <td>    0.006849</td>\n",
        "      <td>   -0.892659</td>\n",
        "      <td>    0.609451</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>    1.008282</td>\n",
        "      <td>    1.016298</td>\n",
        "      <td>    0.979109</td>\n",
        "      <td>    0.970575</td>\n",
        "      <td>    4.538834</td>\n",
        "      <td>    0.989128</td>\n",
        "      <td>    2.118819</td>\n",
        "      <td>    2.232256</td>\n",
        "      <td>    1.001064</td>\n",
        "      <td>    1.013520</td>\n",
        "      <td>...</td>\n",
        "      <td>    1.011645</td>\n",
        "      <td>    1.001375</td>\n",
        "      <td>    2.239939</td>\n",
        "      <td>    1.022456</td>\n",
        "      <td>    2.121281</td>\n",
        "      <td>    1.007044</td>\n",
        "      <td>    2.227876</td>\n",
        "      <td>    0.997635</td>\n",
        "      <td>    2.022022</td>\n",
        "      <td>    2.045439</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   -3.365711</td>\n",
        "      <td>   -3.492086</td>\n",
        "      <td>   -2.695602</td>\n",
        "      <td>   -3.460471</td>\n",
        "      <td>  -16.421901</td>\n",
        "      <td>   -3.041250</td>\n",
        "      <td>   -7.224761</td>\n",
        "      <td>   -6.509084</td>\n",
        "      <td>   -3.145588</td>\n",
        "      <td>   -2.749812</td>\n",
        "      <td>...</td>\n",
        "      <td>   -3.379194</td>\n",
        "      <td>   -2.971125</td>\n",
        "      <td>   -7.840890</td>\n",
        "      <td>   -2.999564</td>\n",
        "      <td>   -7.124105</td>\n",
        "      <td>   -2.952358</td>\n",
        "      <td>   -5.452254</td>\n",
        "      <td>   -3.473913</td>\n",
        "      <td>   -8.051722</td>\n",
        "      <td>   -7.799086</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>   -0.669010</td>\n",
        "      <td>   -0.693937</td>\n",
        "      <td>   -0.698830</td>\n",
        "      <td>   -0.617557</td>\n",
        "      <td>   -1.801997</td>\n",
        "      <td>   -0.732265</td>\n",
        "      <td>   -0.838619</td>\n",
        "      <td>   -1.604037</td>\n",
        "      <td>   -0.677562</td>\n",
        "      <td>   -0.682220</td>\n",
        "      <td>...</td>\n",
        "      <td>   -0.659457</td>\n",
        "      <td>   -0.696032</td>\n",
        "      <td>   -2.121943</td>\n",
        "      <td>   -0.664550</td>\n",
        "      <td>   -1.879247</td>\n",
        "      <td>   -0.642861</td>\n",
        "      <td>   -1.059786</td>\n",
        "      <td>   -0.691162</td>\n",
        "      <td>   -2.220126</td>\n",
        "      <td>   -0.565041</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>    0.027895</td>\n",
        "      <td>   -0.033194</td>\n",
        "      <td>    0.008145</td>\n",
        "      <td>    0.002327</td>\n",
        "      <td>    0.862818</td>\n",
        "      <td>    0.027041</td>\n",
        "      <td>    0.582321</td>\n",
        "      <td>    0.018809</td>\n",
        "      <td>    0.022092</td>\n",
        "      <td>   -0.036110</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.049416</td>\n",
        "      <td>    0.049778</td>\n",
        "      <td>   -0.568262</td>\n",
        "      <td>   -0.028097</td>\n",
        "      <td>   -0.493575</td>\n",
        "      <td>    0.037732</td>\n",
        "      <td>    0.455474</td>\n",
        "      <td>    0.038284</td>\n",
        "      <td>   -0.855470</td>\n",
        "      <td>    0.779944</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>    0.762520</td>\n",
        "      <td>    0.682753</td>\n",
        "      <td>    0.661434</td>\n",
        "      <td>    0.640743</td>\n",
        "      <td>    3.843172</td>\n",
        "      <td>    0.671456</td>\n",
        "      <td>    1.913664</td>\n",
        "      <td>    1.438304</td>\n",
        "      <td>    0.741310</td>\n",
        "      <td>    0.665364</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.747031</td>\n",
        "      <td>    0.699917</td>\n",
        "      <td>    0.939348</td>\n",
        "      <td>    0.651374</td>\n",
        "      <td>    1.005795</td>\n",
        "      <td>    0.691800</td>\n",
        "      <td>    2.122157</td>\n",
        "      <td>    0.693535</td>\n",
        "      <td>    0.388698</td>\n",
        "      <td>    1.992193</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>    3.326246</td>\n",
        "      <td>    3.583870</td>\n",
        "      <td>    2.546507</td>\n",
        "      <td>    3.088738</td>\n",
        "      <td>   17.565345</td>\n",
        "      <td>    3.102997</td>\n",
        "      <td>    7.592666</td>\n",
        "      <td>    7.130097</td>\n",
        "      <td>    3.145258</td>\n",
        "      <td>    3.919426</td>\n",
        "      <td>...</td>\n",
        "      <td>    2.844792</td>\n",
        "      <td>    3.688047</td>\n",
        "      <td>    7.160379</td>\n",
        "      <td>    3.353631</td>\n",
        "      <td>    6.005818</td>\n",
        "      <td>    3.420561</td>\n",
        "      <td>    6.603499</td>\n",
        "      <td>    3.492548</td>\n",
        "      <td>    5.774120</td>\n",
        "      <td>    6.803984</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 40 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "                0            1            2            3            4   \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
        "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
        "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
        "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
        "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
        "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
        "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
        "\n",
        "                5            6            7            8            9   \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597   \n",
        "std       0.989128     2.118819     2.232256     1.001064     1.013520   \n",
        "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812   \n",
        "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220   \n",
        "50%       0.027041     0.582321     0.018809     0.022092    -0.036110   \n",
        "75%       0.671456     1.913664     1.438304     0.741310     0.665364   \n",
        "max       3.102997     7.592666     7.130097     3.145258     3.919426   \n",
        "\n",
        "          ...                30           31           32           33  \\\n",
        "count     ...       1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean      ...          0.030651     0.022951    -0.542491    -0.011608   \n",
        "std       ...          1.011645     1.001375     2.239939     1.022456   \n",
        "min       ...         -3.379194    -2.971125    -7.840890    -2.999564   \n",
        "25%       ...         -0.659457    -0.696032    -2.121943    -0.664550   \n",
        "50%       ...          0.049416     0.049778    -0.568262    -0.028097   \n",
        "75%       ...          0.747031     0.699917     0.939348     0.651374   \n",
        "max       ...          2.844792     3.688047     7.160379     3.353631   \n",
        "\n",
        "                34           35           36           37           38  \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean     -0.483507     0.033371     0.567185     0.006849    -0.892659   \n",
        "std       2.121281     1.007044     2.227876     0.997635     2.022022   \n",
        "min      -7.124105    -2.952358    -5.452254    -3.473913    -8.051722   \n",
        "25%      -1.879247    -0.642861    -1.059786    -0.691162    -2.220126   \n",
        "50%      -0.493575     0.037732     0.455474     0.038284    -0.855470   \n",
        "75%       1.005795     0.691800     2.122157     0.693535     0.388698   \n",
        "max       6.005818     3.420561     6.603499     3.492548     5.774120   \n",
        "\n",
        "                39  \n",
        "count  1000.000000  \n",
        "mean      0.609451  \n",
        "std       2.045439  \n",
        "min      -7.799086  \n",
        "25%      -0.565041  \n",
        "50%       0.779944  \n",
        "75%       1.992193  \n",
        "max       6.803984  \n",
        "\n",
        "[8 rows x 40 columns]"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Train-Test-Split"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "print \"Train data shape: %r, Train target shape: %r\" % (X_train.shape, y_train.shape)\n",
      "print \"Test data shape: %r, Test target shape: %r\" % (X_test.shape, y_test.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train data shape: (800, 40), Train target shape: (800,)\n",
        "Test data shape: (200, 40), Test target shape: (200,)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ss = StandardScaler()\n",
      "X_s = ss.fit_transform(X)\n",
      "X_pred_s = ss.fit_transform(X_pred)\n",
      "\n",
      "print X_s.shape, X_pred_s.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 40) (9000, 40)\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Get best features by forest model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trees = ExtraTreesClassifier(n_estimators=100)\n",
      "trees.fit(X_s, y)\n",
      "pd.DataFrame(trees.feature_importances_).plot(kind='barh')\n",
      "selected_features = np.where(trees.feature_importances_ > 0.015)[0]\n",
      "\n",
      "X_selected = X[:, selected_features]\n",
      "X_pred_selected = X_pred[:, selected_features]\n",
      "print X_selected.shape, X_pred_selected.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 19) (9000, 19)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAFtCAYAAAAqMk/SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZKkAfJwJUmSNEAeriRJkgbo/wOCxqJmXF4eJAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10b226b50>"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Support Vector Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "svc = SVC(probability=True)\n",
      "\n",
      "params = {'gamma': np.logspace(-4, 0, 5)\n",
      "          }\n",
      "\n",
      "gs = GridSearchCV(svc, params, cv=3, \n",
      "                  scoring='accuracy', \n",
      "                  n_jobs=4,\n",
      "                  verbose=1)\n",
      "\n",
      "_ = gs.fit(X_train_selected, y_train)\n",
      "\n",
      "print \"GS Best Score: %0.2f\" % gs.best_score_\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=4)]: Done   1 jobs       | elapsed:    0.1s\n",
        "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.3s remaining:    0.2s\n",
        "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:    0.6s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GS Best Score: 0.91\n",
        "GS Best Params: {'gamma': 0.01}\n",
        "CPU times: user 201 ms, sys: 32.2 ms, total: 233 ms\n",
        "Wall time: 912 ms\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "svc.set_params(**gs.best_params_)\n",
      "svc.fit(X_train_selected, y_train)\n",
      "\n",
      "training_accuracy = svc.score(X_train, y_train)\n",
      "test_accuracy = svc.score(X_test, y_test)\n",
      "\n",
      "print \"Training Score: %0.2f%%\" % (100 * training_accuracy)\n",
      "print \"Test Score: %0.2f%%\" % (100 * test_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "X.shape[1] = 40 should be equal to 15, the number of features at training time",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-65-e5fe0aa111e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \"\"\"\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    403\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[1;32m    404\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 40 should be equal to 15, the number of features at training time"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Extra Trees Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "et = ExtraTreesClassifier(n_estimators=50)\n",
      "et.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "{'bootstrap': False,\n",
        " 'compute_importances': None,\n",
        " 'criterion': 'gini',\n",
        " 'max_depth': None,\n",
        " 'max_features': 'auto',\n",
        " 'max_leaf_nodes': None,\n",
        " 'min_density': None,\n",
        " 'min_samples_leaf': 1,\n",
        " 'min_samples_split': 2,\n",
        " 'n_estimators': 50,\n",
        " 'n_jobs': 1,\n",
        " 'oob_score': False,\n",
        " 'random_state': None,\n",
        " 'verbose': 0}"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "\n",
      "et = ExtraTreesClassifier(n_estimators=50)\n",
      "\n",
      "params = {'max_depth': [2, 3, 4, 6, 8],\n",
      "          'min_samples_leaf': [3, 5, 7, 8, 10],\n",
      "          'max_features': [1.0, 0.3, 0.1],\n",
      "          }\n",
      "\n",
      "n_subsamples = 800\n",
      "X_small_train, y_small_train = X_train[:n_subsamples], y_train[:n_subsamples]\n",
      "\n",
      "gs = GridSearchCV(et, params, cv=3, \n",
      "                  scoring='accuracy', \n",
      "                  n_jobs=4,\n",
      "                  verbose=1)\n",
      "\n",
      "_ = gs.fit(X_small_train, y_small_train)\n",
      "\n",
      "print \"GS Best Score: %0.2f\" % gs.best_score_\n",
      "print \"GS Best Params:\", gs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=4)]: Done   1 jobs       | elapsed:    0.1s\n",
        "[Parallel(n_jobs=4)]: Done  50 jobs       | elapsed:    1.2s\n",
        "[Parallel(n_jobs=4)]: Done 200 jobs       | elapsed:    5.1s\n",
        "[Parallel(n_jobs=4)]: Done 219 out of 225 | elapsed:    5.5s remaining:    0.2s\n",
        "[Parallel(n_jobs=4)]: Done 225 out of 225 | elapsed:    5.6s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GS Best Score: 0.86\n",
        "GS Best Params: {'max_features': 1.0, 'max_depth': 6, 'min_samples_leaf': 3}\n",
        "CPU times: user 777 ms, sys: 144 ms, total: 921 ms\n",
        "Wall time: 5.85 s\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
      "\n",
      "et.set_params(**gs.best_params_)\n",
      "et.fit(X_train_selected, y_train)\n",
      "\n",
      "training_accuracy = et.score(X_train, y_train)\n",
      "test_accuracy = et.score(X_test, y_test)\n",
      "\n",
      "print \"Training Score: %0.2f%%\" % (100 * training_accuracy)\n",
      "print \"Test Score: %0.2f%%\" % (100 * test_accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Invalid parameter gamma for estimator ExtraTreesClassifier",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-38-a0693542c28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     raise ValueError('Invalid parameter %s ' 'for estimator %s'\n\u001b[0;32m--> 256\u001b[0;31m                                      % (key, self.__class__.__name__))\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Invalid parameter gamma for estimator ExtraTreesClassifier"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Accuracy Score"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import cross_val_score\n",
      "\n",
      "scores = cross_val_score(clf, pca.transform(X), y)\n",
      "\n",
      "print \"CV Score (min): %0.2f%%\" % (100 * scores.min())\n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())\n",
      "print \"CV Score (max): %0.2f%%\" % (100 * scores.max())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (min): 98.20%\n",
        "CV Score (mean): 98.90%\n",
        "CV Score (max): 99.40%\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Generate Predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = pd.DataFrame(index=np.arange(1, len(X_pred) + 1))\n",
      "pred['Solution'] = clf.predict(pca.transform(X_pred))\n",
      "# pred.to_csv('gmm_pca.csv', index_label='ID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('../style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}