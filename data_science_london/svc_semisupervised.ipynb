{
 "metadata": {
  "name": "",
  "signature": "sha256:f83ba948fcb6a6e4a1ce49078df71c1e89a2eadca89fb3af3c2328d1d538ddd2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Data Science London<span/>\n",
      "<img src=\"../images/ds.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#SVC - SemiSupervised\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Preliminaries\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.preprocessing import StandardScaler, normalize\n",
      "from sklearn.ensemble import ExtraTreesClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.mixture import GMM, VBGMM\n",
      "\n",
      "sns.set(style=\"white\")\n",
      "plt.rc(\"figure\", figsize=(10, 6))\n",
      "np.set_printoptions(precision=4)\n",
      "\n",
      "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\", \"#467821\", \"#D55E00\",\n",
      "          \"#CC79A7\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\"]\n",
      "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
      "\n",
      "import warnings\n",
      "warnings.simplefilter('ignore', DeprecationWarning)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "[back to top](#contents)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_df = pd.read_csv(\"../data_science_london/data/train.csv\", header=None)\n",
      "y_df = pd.read_csv(\"../data_science_london/data/trainLabels.csv\", header=None)\n",
      "X_pred_df = pd.read_csv(\"../data_science_london/data/test.csv\", header=None)\n",
      "\n",
      "X = X_df.values\n",
      "y = y_df[0].values\n",
      "X_pred = X_pred_df.values\n",
      "X_combined = np.r_[X, X_pred]\n",
      "\n",
      "print X.shape, y.shape, X_pred.shape, X_combined.shape\n",
      "\n",
      "X_df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 40) (1000,) (9000, 40) (10000, 40)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>30</th>\n",
        "      <th>31</th>\n",
        "      <th>32</th>\n",
        "      <th>33</th>\n",
        "      <th>34</th>\n",
        "      <th>35</th>\n",
        "      <th>36</th>\n",
        "      <th>37</th>\n",
        "      <th>38</th>\n",
        "      <th>39</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td>...</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "      <td> 1000.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td>    0.025596</td>\n",
        "      <td>   -0.024526</td>\n",
        "      <td>   -0.024088</td>\n",
        "      <td>   -0.002271</td>\n",
        "      <td>    1.092329</td>\n",
        "      <td>   -0.006250</td>\n",
        "      <td>    0.497342</td>\n",
        "      <td>   -0.037883</td>\n",
        "      <td>    0.026391</td>\n",
        "      <td>   -0.003597</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.030651</td>\n",
        "      <td>    0.022951</td>\n",
        "      <td>   -0.542491</td>\n",
        "      <td>   -0.011608</td>\n",
        "      <td>   -0.483507</td>\n",
        "      <td>    0.033371</td>\n",
        "      <td>    0.567185</td>\n",
        "      <td>    0.006849</td>\n",
        "      <td>   -0.892659</td>\n",
        "      <td>    0.609451</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td>    1.008282</td>\n",
        "      <td>    1.016298</td>\n",
        "      <td>    0.979109</td>\n",
        "      <td>    0.970575</td>\n",
        "      <td>    4.538834</td>\n",
        "      <td>    0.989128</td>\n",
        "      <td>    2.118819</td>\n",
        "      <td>    2.232256</td>\n",
        "      <td>    1.001064</td>\n",
        "      <td>    1.013520</td>\n",
        "      <td>...</td>\n",
        "      <td>    1.011645</td>\n",
        "      <td>    1.001375</td>\n",
        "      <td>    2.239939</td>\n",
        "      <td>    1.022456</td>\n",
        "      <td>    2.121281</td>\n",
        "      <td>    1.007044</td>\n",
        "      <td>    2.227876</td>\n",
        "      <td>    0.997635</td>\n",
        "      <td>    2.022022</td>\n",
        "      <td>    2.045439</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   -3.365711</td>\n",
        "      <td>   -3.492086</td>\n",
        "      <td>   -2.695602</td>\n",
        "      <td>   -3.460471</td>\n",
        "      <td>  -16.421901</td>\n",
        "      <td>   -3.041250</td>\n",
        "      <td>   -7.224761</td>\n",
        "      <td>   -6.509084</td>\n",
        "      <td>   -3.145588</td>\n",
        "      <td>   -2.749812</td>\n",
        "      <td>...</td>\n",
        "      <td>   -3.379194</td>\n",
        "      <td>   -2.971125</td>\n",
        "      <td>   -7.840890</td>\n",
        "      <td>   -2.999564</td>\n",
        "      <td>   -7.124105</td>\n",
        "      <td>   -2.952358</td>\n",
        "      <td>   -5.452254</td>\n",
        "      <td>   -3.473913</td>\n",
        "      <td>   -8.051722</td>\n",
        "      <td>   -7.799086</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td>   -0.669010</td>\n",
        "      <td>   -0.693937</td>\n",
        "      <td>   -0.698830</td>\n",
        "      <td>   -0.617557</td>\n",
        "      <td>   -1.801997</td>\n",
        "      <td>   -0.732265</td>\n",
        "      <td>   -0.838619</td>\n",
        "      <td>   -1.604037</td>\n",
        "      <td>   -0.677562</td>\n",
        "      <td>   -0.682220</td>\n",
        "      <td>...</td>\n",
        "      <td>   -0.659457</td>\n",
        "      <td>   -0.696032</td>\n",
        "      <td>   -2.121943</td>\n",
        "      <td>   -0.664550</td>\n",
        "      <td>   -1.879247</td>\n",
        "      <td>   -0.642861</td>\n",
        "      <td>   -1.059786</td>\n",
        "      <td>   -0.691162</td>\n",
        "      <td>   -2.220126</td>\n",
        "      <td>   -0.565041</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td>    0.027895</td>\n",
        "      <td>   -0.033194</td>\n",
        "      <td>    0.008145</td>\n",
        "      <td>    0.002327</td>\n",
        "      <td>    0.862818</td>\n",
        "      <td>    0.027041</td>\n",
        "      <td>    0.582321</td>\n",
        "      <td>    0.018809</td>\n",
        "      <td>    0.022092</td>\n",
        "      <td>   -0.036110</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.049416</td>\n",
        "      <td>    0.049778</td>\n",
        "      <td>   -0.568262</td>\n",
        "      <td>   -0.028097</td>\n",
        "      <td>   -0.493575</td>\n",
        "      <td>    0.037732</td>\n",
        "      <td>    0.455474</td>\n",
        "      <td>    0.038284</td>\n",
        "      <td>   -0.855470</td>\n",
        "      <td>    0.779944</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td>    0.762520</td>\n",
        "      <td>    0.682753</td>\n",
        "      <td>    0.661434</td>\n",
        "      <td>    0.640743</td>\n",
        "      <td>    3.843172</td>\n",
        "      <td>    0.671456</td>\n",
        "      <td>    1.913664</td>\n",
        "      <td>    1.438304</td>\n",
        "      <td>    0.741310</td>\n",
        "      <td>    0.665364</td>\n",
        "      <td>...</td>\n",
        "      <td>    0.747031</td>\n",
        "      <td>    0.699917</td>\n",
        "      <td>    0.939348</td>\n",
        "      <td>    0.651374</td>\n",
        "      <td>    1.005795</td>\n",
        "      <td>    0.691800</td>\n",
        "      <td>    2.122157</td>\n",
        "      <td>    0.693535</td>\n",
        "      <td>    0.388698</td>\n",
        "      <td>    1.992193</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td>    3.326246</td>\n",
        "      <td>    3.583870</td>\n",
        "      <td>    2.546507</td>\n",
        "      <td>    3.088738</td>\n",
        "      <td>   17.565345</td>\n",
        "      <td>    3.102997</td>\n",
        "      <td>    7.592666</td>\n",
        "      <td>    7.130097</td>\n",
        "      <td>    3.145258</td>\n",
        "      <td>    3.919426</td>\n",
        "      <td>...</td>\n",
        "      <td>    2.844792</td>\n",
        "      <td>    3.688047</td>\n",
        "      <td>    7.160379</td>\n",
        "      <td>    3.353631</td>\n",
        "      <td>    6.005818</td>\n",
        "      <td>    3.420561</td>\n",
        "      <td>    6.603499</td>\n",
        "      <td>    3.492548</td>\n",
        "      <td>    5.774120</td>\n",
        "      <td>    6.803984</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>8 rows \u00d7 40 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "                0            1            2            3            4   \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
        "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
        "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
        "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
        "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
        "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
        "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
        "\n",
        "                5            6            7            8            9   \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597   \n",
        "std       0.989128     2.118819     2.232256     1.001064     1.013520   \n",
        "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812   \n",
        "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220   \n",
        "50%       0.027041     0.582321     0.018809     0.022092    -0.036110   \n",
        "75%       0.671456     1.913664     1.438304     0.741310     0.665364   \n",
        "max       3.102997     7.592666     7.130097     3.145258     3.919426   \n",
        "\n",
        "          ...                30           31           32           33  \\\n",
        "count     ...       1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean      ...          0.030651     0.022951    -0.542491    -0.011608   \n",
        "std       ...          1.011645     1.001375     2.239939     1.022456   \n",
        "min       ...         -3.379194    -2.971125    -7.840890    -2.999564   \n",
        "25%       ...         -0.659457    -0.696032    -2.121943    -0.664550   \n",
        "50%       ...          0.049416     0.049778    -0.568262    -0.028097   \n",
        "75%       ...          0.747031     0.699917     0.939348     0.651374   \n",
        "max       ...          2.844792     3.688047     7.160379     3.353631   \n",
        "\n",
        "                34           35           36           37           38  \\\n",
        "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
        "mean     -0.483507     0.033371     0.567185     0.006849    -0.892659   \n",
        "std       2.121281     1.007044     2.227876     0.997635     2.022022   \n",
        "min      -7.124105    -2.952358    -5.452254    -3.473913    -8.051722   \n",
        "25%      -1.879247    -0.642861    -1.059786    -0.691162    -2.220126   \n",
        "50%      -0.493575     0.037732     0.455474     0.038284    -0.855470   \n",
        "75%       1.005795     0.691800     2.122157     0.693535     0.388698   \n",
        "max       6.005818     3.420561     6.603499     3.492548     5.774120   \n",
        "\n",
        "                39  \n",
        "count  1000.000000  \n",
        "mean      0.609451  \n",
        "std       2.045439  \n",
        "min      -7.799086  \n",
        "25%      -0.565041  \n",
        "50%       0.779944  \n",
        "75%       1.992193  \n",
        "max       6.803984  \n",
        "\n",
        "[8 rows x 40 columns]"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = X\n",
      "y_train = y\n",
      "\n",
      "print X_train.shape, y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 40) (1000,)\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###SVC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = SVC(kernel='rbf', C=10, gamma=0.02, probability=True)\n",
      "clf.fit(X_train, y_train)\n",
      "\n",
      "scores = cross_val_score(clf, X_train, y_train)\n",
      " \n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (mean): 90.80%\n"
       ]
      }
     ],
     "prompt_number": 111
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Semi-supervised"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "probas = clf.predict_proba(X_pred)\n",
      "probas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "array([[  2.9175e-06,   1.0000e+00],\n",
        "       [  9.5950e-01,   4.0504e-02],\n",
        "       [  4.6506e-02,   9.5349e-01],\n",
        "       ..., \n",
        "       [  6.5151e-03,   9.9348e-01],\n",
        "       [  9.9952e-01,   4.8447e-04],\n",
        "       [  6.6585e-06,   9.9999e-01]])"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "limit = 0.1 #picking out 90% of good probability\n",
      "good_probas = (probas[:, 0] < 0.05) | (probas[:, 0] > 0.95)\n",
      "good_probas.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "0.61088888888888893"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_new = X_pred[good_probas]\n",
      "y_new = svc_gmm.predict(X_pred)[good_probas]\n",
      "print X_new.shape, y_new.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5498, 40) (5498,)\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train1 = np.vstack((X_train, X_new))\n",
      "y_train1 = np.hstack((y_train, y_new))\n",
      "\n",
      "print X_train1.shape, y_train1.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6498, 40) (6498,)\n"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf1 = SVC(kernel='rbf', C=10, gamma=0.02, probability=True)\n",
      "clf1.fit(X_train1, y_train1)\n",
      "\n",
      "scores = cross_val_score(clf1, X_train, y_train)\n",
      " \n",
      "print \"CV Score (mean): %0.2f%%\" % (100 * scores.mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CV Score (mean): 90.80%\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Generate Predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = pd.DataFrame(index=np.arange(1, len(X_pred) + 1))\n",
      "pred['Solution'] = clf1.predict(X_pred)\n",
      "# pred.to_csv('svc_semisupervised.csv', index_label='ID')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import display, HTML\n",
      "display(HTML(open('../style/custom.css').read()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}